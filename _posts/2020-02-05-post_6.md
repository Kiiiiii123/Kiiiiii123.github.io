### CS285 Lecture5: Policy Gradients
### (1) Today’s Lecture
#### 1. The policy gradient algorithm
#### 2. What does the policy gradient do?
#### 3. Basic variance reduction: causality （因果关系）
#### 4. Basic variance reduction: baselines
#### 5. Policy gradient examples
#### 6. Goals:
##### • Understand policy gradient reinforcement learning 
##### • Understand practical considerations for policy gradients
### (2) Evaluating the RL objective
#### J(θ) is equal to the expectation and we can approximate it using samples. We get an unbiased estimate of the expected reward of our policy.
<p align="center">
<img src="/images/66.png"><br/>
</p>

### (3) Direct policy differentiation
#### Pθ(τ) and πθ(τ) mean exactly the same thing.
<p align="center">
<img src="/images/67.png"><br/>
</p>
