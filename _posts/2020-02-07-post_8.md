### CS285 Lecture7: Value Function Methods
### (1) Today’s Lecture
#### 1. What if we just use a critic, without an actor?
#### 2. Extracting a policy from a value function
#### 3. The Q-learning algorithm
#### 4. Extensions: continuous actions, improvements
#### 5. Goals:
##### • Understand how value functions give rise to policies
##### • Understand the Q-learning algorithm
##### • Understand practical considerations for Q-learning
### (2) Recap: actor-critic
<p align="center">
<img src="/images/123.png"><br/>
</p>

### (3) Can we omit policy gradient completely?
#### 
